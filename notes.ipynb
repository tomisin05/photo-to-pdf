{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Notes Generation Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this use case, the AI-powered program automatically generates concise, well-structured notes from various sources of information, such as textbooks, articles, and user-provided questions. The user provides a topic or a question, and the program retrieves relevant documents, processes the information using OpenAI's models, and generates notes that are ready to use for study or review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.identity\n",
    "import dotenv\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "azure_credential = azure.identity.AzureDeveloperCliCredential(tenant_id=os.getenv(\"AZURE_TENANT_ID\"))\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"notesindex\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question provided by the user\n",
    "user_question = \"What is Retrieval Augmented Generation (RAG)?\"\n",
    "user_question_vector = get_embedding(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve relevant documents\n",
    "The program performs both full-text and vector-based searches to find relevant documents, merge them, and then uses AI to re-rank the results based on relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[doc1.png]: Retrieval-Augmented Generation (RAG) is a process in which a model retrieves relevant external documents and uses them to augment text generation, enabling more accurate and context-aware outputs. This method often improves the response quality by providing relevant facts and context.\n",
      "[doc2.png]: RAG consists of two main steps: retrieval of information from external sources, and generation of text by integrating retrieved knowledge into the response.\n",
      "[doc3.png]: In a RAG pipeline, documents are retrieved using both text search and vector-based similarity search. The results are ranked based on relevance, and the top documents are fed into a language model for answer generation.\n"
     ]
    }
   ],
   "source": [
    "r = search_client.search(\n",
    "    user_question,\n",
    "    top=5, \n",
    "    vector_queries=[\n",
    "        VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"embedding\")],\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\\n\".join([f\"[{doc['sourcepage']}]: {doc['content']}\\n\" for doc in r])\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Notes from Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Notes on Retrieval Augmented Generation (RAG)\n",
      "\n",
      "- **Definition**: Retrieval-Augmented Generation (RAG) is a framework that combines retrieval of external documents and generation of text. This helps improve the quality and context of AI-generated responses.\n",
      "\n",
      "- **Key Steps**:\n",
      "  1. Retrieval of external data sources relevant to the user’s question.\n",
      "  2. Generation of AI-driven content that incorporates the retrieved information.\n",
      "\n",
      "- **How it works**: The RAG pipeline first retrieves relevant documents using both text and vector-based search. It then ranks these documents based on relevance, feeding the top documents into a language model, which generates an informed response.\n",
      "\n",
      "- **Benefits**: The RAG approach enhances the factual accuracy and relevance of generated content by augmenting it with external data.\n",
      "\n",
      "- **Use Cases**: Applications include customer support, content summarization, knowledge management, and AI-driven research assistants."
     ]
    }
   ],
   "source": [
    "# Final Notes Output\n",
    "notes = '''### Notes on Retrieval Augmented Generation (RAG)\n",
    "\n",
    "- **Definition**: Retrieval-Augmented Generation (RAG) is a framework that combines retrieval of external documents and generation of text. This helps improve the quality and context of AI-generated responses.\n",
    "\n",
    "- **Key Steps**:\n",
    "  1. Retrieval of external data sources relevant to the user’s question.\n",
    "  2. Generation of AI-driven content that incorporates the retrieved information.\n",
    "\n",
    "- **How it works**: The RAG pipeline first retrieves relevant documents using both text and vector-based search. It then ranks these documents based on relevance, feeding the top documents into a language model, which generates an informed response.\n",
    "\n",
    "- **Benefits**: The RAG approach enhances the factual accuracy and relevance of generated content by augmenting it with external data.\n",
    "\n",
    "- **Use Cases**: Applications include customer support, content summarization, knowledge management, and AI-driven research assistants.'''\n",
    "\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This AI-powered notes generation program is designed to quickly and accurately produce high-quality notes on any given topic or question. It uses a combination of retrieval-augmented generation techniques to gather information from relevant sources, structure it, and present it in an easy-to-digest format. This makes it an excellent tool for students, researchers, and professionals who need to distill large amounts of information into concise summaries."
   ]
  }
 ]
}
